#!/usr/bin/env python3
"""
Comprehensive SEO & Sitemap Optimization Test
Tests SEO improvements, sitemap synchronization, and validates implementation
"""

import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
import json
import os
import sys

def test_seo_optimizations():
    """Test specific SEO optimizations"""
    
    print("üöÄ SEO OPTIMIZATION VALIDATION TEST")
    print("=" * 60)
    
    base_url = "https://prajitdas.github.io/"
    
    try:
        response = requests.get(base_url, timeout=10)
        if response.status_code != 200:
            print(f"‚ùå Could not fetch website: {response.status_code}")
            return False
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Test Results
        tests_passed = 0
        total_tests = 0
        
        print("üîç TESTING SEO IMPROVEMENTS:")
        print("-" * 40)
        
        # Test 1: Enhanced Title Tag
        total_tests += 1
        title = soup.find('title')
        if title and 'Software Engineering Leader' in title.text:
            print("‚úÖ Enhanced title tag with professional keywords")
            tests_passed += 1
        else:
            print("‚ùå Title tag not properly enhanced")
        
        # Test 2: Optimized Meta Description
        total_tests += 1
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc:
            desc_content = meta_desc.get('content', '')
            if 120 <= len(desc_content) <= 160 and 'Cisco Systems' in desc_content:
                print("‚úÖ Meta description optimized (length & content)")
                tests_passed += 1
            else:
                print(f"‚ùå Meta description needs work (length: {len(desc_content)})")
        else:
            print("‚ùå Meta description missing")
        
        # Test 3: Canonical URL
        total_tests += 1
        canonical = soup.find('link', attrs={'rel': 'canonical'})
        if canonical and canonical.get('href') == base_url:
            print("‚úÖ Canonical URL properly set")
            tests_passed += 1
        else:
            print("‚ùå Canonical URL missing or incorrect")
        
        # Test 4: Robots Meta Tag
        total_tests += 1
        robots_meta = soup.find('meta', attrs={'name': 'robots'})
        if robots_meta and 'index, follow' in robots_meta.get('content', ''):
            print("‚úÖ Robots meta tag configured")
            tests_passed += 1
        else:
            print("‚ùå Robots meta tag missing or incorrect")
        
        # Test 5: Open Graph Tags
        total_tests += 1
        og_tags = soup.find_all('meta', attrs={'property': lambda x: x and x.startswith('og:')})
        required_og = ['og:title', 'og:description', 'og:url', 'og:type', 'og:image']
        og_properties = [tag.get('property') for tag in og_tags]
        if all(prop in og_properties for prop in required_og):
            print("‚úÖ Open Graph tags complete")
            tests_passed += 1
        else:
            missing = [prop for prop in required_og if prop not in og_properties]
            print(f"‚ùå Missing Open Graph tags: {missing}")
        
        # Test 6: Twitter Card Tags
        total_tests += 1
        twitter_tags = soup.find_all('meta', attrs={'property': lambda x: x and x.startswith('twitter:')})
        required_twitter = ['twitter:card', 'twitter:title', 'twitter:description']
        twitter_properties = [tag.get('property') for tag in twitter_tags]
        if all(prop in twitter_properties for prop in required_twitter):
            print("‚úÖ Twitter Card tags complete")
            tests_passed += 1
        else:
            missing = [prop for prop in required_twitter if prop not in twitter_properties]
            print(f"‚ùå Missing Twitter Card tags: {missing}")
        
        # Test 7: JSON-LD Structured Data
        total_tests += 1
        json_ld_scripts = soup.find_all('script', type='application/ld+json')
        if json_ld_scripts:
            try:
                for script in json_ld_scripts:
                    data = json.loads(script.string)
                    if data.get('@type') == 'Person' and 'Prajit Kumar Das' in data.get('name', ''):
                        print("‚úÖ JSON-LD structured data implemented")
                        tests_passed += 1
                        break
                else:
                    print("‚ùå JSON-LD structured data incomplete")
            except json.JSONDecodeError:
                print("‚ùå JSON-LD structured data malformed")
        else:
            print("‚ùå JSON-LD structured data missing")
        
        # Test 8: Language Declaration
        total_tests += 1
        html_tag = soup.find('html')
        if html_tag and html_tag.get('lang') == 'en':
            print("‚úÖ Language declaration proper")
            tests_passed += 1
        else:
            print("‚ùå Language declaration missing or incorrect")
        
        # Test 9: Professional Keywords
        total_tests += 1
        meta_keywords = soup.find('meta', attrs={'name': 'keywords'})
        if meta_keywords:
            keywords = meta_keywords.get('content', '')
            professional_terms = ['Software Engineering', 'Cisco Systems', 'Mobile Security', 'PhD']
            if any(term in keywords for term in professional_terms):
                print("‚úÖ Professional keywords included")
                tests_passed += 1
            else:
                print("‚ùå Professional keywords missing")
        else:
            print("‚ùå Keywords meta tag missing")
        
        # Test 10: Enhanced Sitemap
        total_tests += 1
        try:
            sitemap_response = requests.get(f"{base_url}sitemap.xml", timeout=10)
            if sitemap_response.status_code == 200:
                sitemap_content = sitemap_response.text
                if sitemap_content.count('<url>') > 1:  # More than just homepage
                    print("‚úÖ Enhanced sitemap with multiple URLs")
                    tests_passed += 1
                else:
                    print("‚ùå Sitemap needs more URLs")
            else:
                print("‚ùå Sitemap not accessible")
        except:
            print("‚ùå Sitemap test failed")
        
        # Summary
        print("\n" + "=" * 60)
        print(f"üéØ SEO OPTIMIZATION RESULTS: {tests_passed}/{total_tests} tests passed")
        print(f"üìä Success Rate: {(tests_passed/total_tests)*100:.1f}%")
        
        if tests_passed >= 8:
            print("üéâ EXCELLENT! SEO optimizations successfully implemented")
            return True
        elif tests_passed >= 6:
            print("üëç GOOD! Most SEO optimizations in place, minor improvements needed")
            return True
        else:
            print("‚ö†Ô∏è NEEDS WORK! Significant SEO improvements required")
            return False
        
    except Exception as e:
        print(f"‚ùå Error testing SEO optimizations: {e}")
        return False

def test_local_sitemap_synchronization():
    """Test local sitemap synchronization - skip HTML sitemap as it's not wanted"""
    
    print("\nüó∫Ô∏è SITEMAP SYNCHRONIZATION TEST:")
    print("-" * 40)
    
    try:
        # Get project root - updated for new structure  
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))
        
        sitemap_xml = os.path.join(project_root, 'sitemap.xml')
        ror_xml = os.path.join(project_root, 'ror.xml')
        
        # Parse sitemap.xml
        tree = ET.parse(sitemap_xml)
        root = tree.getroot()
        ns = {'sitemap': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
        xml_urls = []
        
        for url_elem in root.findall('.//sitemap:url', ns):
            loc = url_elem.find('sitemap:loc', ns)
            if loc is not None:
                xml_urls.append(loc.text)
        
        # Parse ror.xml
        ror_tree = ET.parse(ror_xml)
        ror_root = ror_tree.getroot()
        ror_urls = []
        
        for item in ror_root.findall('.//item'):
            link = item.find('link')
            if link is not None:
                ror_urls.append(link.text)
        
        print(f"üìÑ XML URLs: {len(xml_urls)}")
        print(f"üìÑ ROR URLs: {len(ror_urls)}")
        
        # Test synchronization between XML and ROR (skip HTML sitemap)
        xml_urls_set = set(xml_urls)
        ror_urls_set = set(ror_urls)
        
        if xml_urls_set == ror_urls_set and len(xml_urls) >= 4:
            print("‚úÖ XML and ROR sitemaps synchronized with specific files")
            return True
        else:
            print("‚ùå Sitemap synchronization issues detected between XML and ROR")
            return False
            
    except Exception as e:
        print(f"‚ùå Sitemap synchronization error: {e}")
        return False

def test_sitemap_enhancement():
    """Test remote sitemap improvements"""
    
    print("\nüåê REMOTE SITEMAP VALIDATION:")
    print("-" * 40)
    
    try:
        sitemap_url = "https://prajitdas.github.io/sitemap.xml"
        response = requests.get(sitemap_url, timeout=10)
        
        if response.status_code == 200:
            sitemap_content = response.text
            
            # Count URLs
            url_count = sitemap_content.count('<url>')
            print(f"Remote URLs in sitemap: {url_count}")
            
            # Check for specific files (not directories)
            specific_files = [
                'resume-prajit-das-032225.pdf',
                'kat-austen-the-trouble-with-wearables.pdf',
                'MobileAccessControl.owl'
            ]
            
            file_count = sum(1 for file in specific_files if file in sitemap_content)
            print(f"Specific files indexed: {file_count}/{len(specific_files)}")
            
            if url_count >= 4 and file_count >= 2:
                print("‚úÖ Remote sitemap properly configured")
                return True
            else:
                print("‚ùå Remote sitemap needs updates")
                return False
        else:
            print(f"‚ùå Remote sitemap not accessible: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Remote sitemap test error: {e}")
        return False

def generate_consolidated_summary():
    """Generate consolidated SEO and Sitemap summary"""
    
    print(f"\nüìã SEO & SITEMAP OPTIMIZATION SUMMARY:")
    print("=" * 60)
    
    optimizations = [
        "‚úÖ Enhanced title tag with professional keywords",
        "‚úÖ Optimized meta description (120-160 characters)",  
        "‚úÖ Added canonical URL for duplicate content prevention",
        "‚úÖ Implemented robots meta tag for search engine guidance",
        "‚úÖ Complete Open Graph meta tags for social media",
        "‚úÖ Twitter Card meta tags for enhanced social sharing",
        "‚úÖ JSON-LD structured data for rich snippets",
        "‚úÖ Professional keywords meta tag",
        "‚úÖ Synchronized sitemaps (XML, ROR)",
        "‚úÖ File-specific indexing (not directories)",
        "‚úÖ SEO-optimized sitemap descriptions",
        "‚úÖ Proper sitemap priorities and frequencies"
    ]
    
    for optimization in optimizations:
        print(optimization)
    
    print(f"\nüéØ COMBINED BENEFITS:")
    print("-" * 20)
    print("‚Ä¢ Better search engine rankings and discoverability")
    print("‚Ä¢ Enhanced social media sharing capabilities")
    print("‚Ä¢ Rich snippets in search results")
    print("‚Ä¢ Professional keyword optimization")
    print("‚Ä¢ Direct file access via sitemaps")
    print("‚Ä¢ Synchronized multi-format sitemaps (XML, ROR)")
    print("‚Ä¢ Improved mobile and desktop SEO performance")

if __name__ == "__main__":
    seo_success = test_seo_optimizations()
    local_sitemap_success = test_local_sitemap_synchronization()
    remote_sitemap_success = test_sitemap_enhancement()
    
    total_success = seo_success and local_sitemap_success and remote_sitemap_success
    
    generate_consolidated_summary()
    
    if total_success:
        print("\nüéâ ALL SEO & SITEMAP OPTIMIZATIONS SUCCESSFUL!")
        sys.exit(0)
    else:
        print("\n‚ö†Ô∏è Some SEO or sitemap optimizations need attention")
        sys.exit(1)